{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICAIL2021 experiments.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "ffCpjOnaIw0n",
        "OZI0XO01ecWq",
        "YgU-01SUfCRk",
        "I1ynkJuVeXav",
        "WxT2CYOvxhJf",
        "xmhJ7yO82JKK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ngV8_0OPER9"
      },
      "source": [
        "# Lex Rosetta: Transfer of Predictive Models Across Languages, Jurisdictions, and Legal Domains\n",
        "\n",
        "This notebook contains the code for the paper:\n",
        "\n",
        "*Jaromir Savelka, Hannes Westermann, Karim Benyekhlef, Charlotte S. Alexander, Jayla C. Grant, David Restrepo Amariles, Rajaa El Hamdani, Sébastien Meeùs, Aurore Troussel, Michał Araszkiewicz, Kevin D. Ashley, Alexandra Ashley, Karl Branting, Mattia Falduti, Matthias Grabmair, Jakub Harašta,Tereza Novotná, Elizabeth Tippett, and Shiwanni Johnson. 2021. Lex Rosetta: Transfer of Predictive Models Across Languages, Jurisdictions, and Legal Domains. In Eighteenth International Conference for Artificial Intelligence and Law (ICAIL’21), June 21–25, 2021, São Paulo, Brazil. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3462757.34661491*\n",
        "\n",
        "The notebook contains the code necessary to load data from annotated multicontextual legal cases. Then, it embeds the individual sentences into a multilingual vector embedding, using [Language-Agnostic SEntence Representations](https://github.com/facebookresearch/LASER). Finally, it trains a gated recurrent unit network to take a new case and predict the label of each sentence. The code to run the experiments presented in the paper and create the visualizations used in the discussion section is included. Notably, that inincludes an evaluation fo how well the model performs when evaluated on a context different from the one it is trained on.\n",
        "\n",
        "This notebook can be run either locally or in the cloud with Google Colab. \n",
        "\n",
        "* On Google Colab **(easier)**. Follow this link: https://colab.research.google.com/drive/1zSsKIPZXp3JdlU5E5GVZox-FiapYm4oD?usp=sharing The notebook will download the data from github. Note that RAM restrictions on colab means that the experiments for H2 and H3 are likely to crash. \n",
        "* Locally: It is recommended to set up a new python environment and run the first cell to install the necessary requirements. Instructions to enable CUDA training, which significantly speeds up execution, is available at https://www.tensorflow.org/install/gpu and https://pytorch.org/get-started/locally/. \n",
        "Certain cells (such as loading the data from github) are only required on Google Colab and can be skipped.\n",
        "\n",
        "\n",
        "Created by Hannes Westermann, Cyberjustice Laboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0GqyiUA3aZV"
      },
      "source": [
        "# Installation\n",
        "\n",
        "Only required first time, or when running online. Can take a while, especially when running locally, since it downloads a number of large packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-leBeF-oqht"
      },
      "source": [
        "## Only required when running locally, these are already installed on Google Colab\n",
        "!pip install tensorflow\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNNh-IAKAYE7"
      },
      "source": [
        "#Install laserembeddings and load the model. Required both on colab and locally.\n",
        "\n",
        "from IPython.display import clear_output\n",
        "!pip install laserembeddings\n",
        "!python -m laserembeddings download-models\n",
        "clear_output()\n",
        "\n",
        "## RESTART RUNTIME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5BCfiaCEd3e"
      },
      "source": [
        "# if you are on colab, run this cell to load the data and switch to the relevant path\n",
        "!git clone https://github.com/lexrosetta/caselaw_functional_segmentation_multilingual.git\n",
        "%cd ./caselaw_functional_segmentation_multilingual/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bcMcgabgF97"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSmxCxSir-uw"
      },
      "source": [
        "Select the datasets and select the chosen annotator where there are multiple annotators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICTz8wE8E_wU"
      },
      "source": [
        "# If you have obtained the canadian data from CanLII, set the following variable to true:\n",
        "include_canada = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bZZ3egS7bJB"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "rootdir = './data/'\n",
        "datasets = []\n",
        "annotators = []\n",
        "if include_canada:\n",
        "    datasets.append(\"Canada-EN-1\")\n",
        "    annotators.append(\"annotator-2\")\n",
        "\n",
        "datasets += [\n",
        "            \"Czech_Republic-CZ-1\",\n",
        "            \"France-FR-1\",\n",
        "            \"Germany-DE-1\",\n",
        "            \"Italy-IT-1\",\n",
        "            \"Poland-PL-1\",\n",
        "            \"United_States-EN-1\",\n",
        "            \"United_States-EN-2\",\n",
        "\n",
        "]\n",
        "annotators += [\n",
        "              \"annotator-1\",\n",
        "              \"annotator-1\",\n",
        "              \"annotator-1\",\n",
        "              \"annotator-1\",\n",
        "              \"annotator-1\",\n",
        "              \"annotator-2\",\n",
        "              \"annotator-1\"\n",
        "]\n",
        "dataframes = {}\n",
        "for i, dataset in enumerate(datasets):\n",
        "    dataframes[dataset] = pd.read_csv(rootdir+dataset+f\"/{annotators[i]}-ICAIL2021.csv\") \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psFzdLUlsPGn"
      },
      "source": [
        "Split the documents into 10 folds, around 10 documents per fold per dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVu0gQvJLzn3"
      },
      "source": [
        "# K-fold split\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "for k,v in dataframes.items():\n",
        "    df = v\n",
        "    docs = df[\"Document\"].unique()\n",
        "    kf = KFold(n_splits=10, shuffle=True, random_state = 42)\n",
        "    current_fold = 0\n",
        "    ref = {}\n",
        "    for train_index, test_index in kf.split(docs):\n",
        "        \n",
        "        for index in test_index:\n",
        "            ref[docs[index]] = current_fold\n",
        "        current_fold += 1\n",
        "    fold_column = []\n",
        "    for doc in df[\"Document\"].values:\n",
        "        fold_column.append(ref[doc])\n",
        "    df[\"fold\"] = fold_column\n",
        "    elements = k.split(\"-\")\n",
        "    df[\"lang\"] = elements[1].lower()\n",
        "    df[\"dataset\"] = k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otbbtbENspFB"
      },
      "source": [
        "Load all sentences into a dataframe. Perform encoding of labels into numerical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO_wnzPBCSIL"
      },
      "source": [
        "lst = []\n",
        "for k,v in dataframes.items():\n",
        "    lst.append(v)\n",
        "data_df=pd.concat(lst, ignore_index=True)\n",
        "data_df = data_df.astype({'Type': 'category'})\n",
        "data_df[\"labels_all\"] = data_df[\"Type\"].cat.codes\n",
        "data_df[\"labels\"] = data_df[\"Type\"].cat.codes\n",
        "data_df = data_df.rename(columns={\"Text\": \"text\"})\n",
        "data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWnOLdOgZTHO"
      },
      "source": [
        "## Verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdIWgX8fuDOo"
      },
      "source": [
        "Quick and dirty verification that labels and folds are distributed as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZptEyassZXLJ"
      },
      "source": [
        "print (data_df.groupby(['dataset','labels']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCcMjX7ZOodu"
      },
      "source": [
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "    print(data_df.groupby(['dataset','fold', 'labels']).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IITX0pC3kWm_"
      },
      "source": [
        "## Sentence embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmGmQWOuPon"
      },
      "source": [
        "Load data into dictionary type that will be used for prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMZtGdrAmK3u"
      },
      "source": [
        "%%time\n",
        "\n",
        "cases = []\n",
        "for doc_name in data_df[\"Document\"].unique():\n",
        "    case_df = data_df.loc[data_df['Document'] == doc_name]\n",
        "    case = {\"file_name\": doc_name, \"sents\": [], \"labels_text\": [], \"labels\": []}\n",
        "    case[\"sents\"] = case_df[\"text\"].values\n",
        "    case[\"labels_text\"] = case_df[\"Type\"].values\n",
        "    case[\"labels\"] = list(case_df[\"labels_all\"].values)\n",
        "    case[\"fold\"] = case_df[\"fold\"].values[0]\n",
        "    case[\"lang\"] = case_df[\"lang\"].values[0]\n",
        "    case[\"dataset\"] = case_df[\"dataset\"].values[0]\n",
        "    cases.append(case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gu4ma0IuXxc"
      },
      "source": [
        "Get list of labels, number of unique labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJsn2plYo65m"
      },
      "source": [
        "unique_labels = list(data_df[\"Type\"].cat.categories)\n",
        "num_labels = data_df[\"labels_all\"].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfnbk9tvuj6w"
      },
      "source": [
        "Establish maximum length (in sentences) of a case. For each case, create an embedding and pad with blank vectors to reach the maximum length of cases in sentences. This cell takes a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y100D1EekapO"
      },
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "import math  \n",
        "from laserembeddings import Laser\n",
        "\n",
        "laser = Laser()\n",
        "\n",
        "\n",
        "#Determine maximal length in sentences of a case for padding\n",
        "max_len = 0\n",
        "for t, case in enumerate(cases):\n",
        "    sents = case[\"sents\"]\n",
        "    case[\"original_length\"] = len(sents)\n",
        "    max_len = max(max_len, len(sents))\n",
        "print (\"Longest sequence: \",max_len)\n",
        "\n",
        "pad_label = 0\n",
        "\n",
        "# Embed senteces in cases and pad until max_len\n",
        "for t, case in enumerate(cases):\n",
        "    sents = case[\"sents\"]\n",
        "    case[\"original_length\"] = len(sents)\n",
        "    diff = (max_len-case[\"original_length\"])\n",
        "    message_embeddings = laser.embed_sentences(case[\"sents\"], lang=case[\"lang\"])\n",
        "    embs = np.array(message_embeddings).tolist()\n",
        "    embs_ext = embs + [[0]*1024]*diff\n",
        "    case[\"embs_ext\"] = embs_ext\n",
        "    case[\"embs\"] = embs\n",
        "    case[\"label_ext\"] = case[\"labels\"]+[pad_label]*diff\n",
        "    print (f\"Created embeddings for case {t+1}/{len(cases)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVlX_SGMsCvX"
      },
      "source": [
        "# Save embedded cases, since previous cell is slow.\n",
        "\n",
        "import pickle\n",
        "with open(\"cases.pkl\", \"wb\") as outfile:\n",
        "    pickle.dump((cases, datasets, data_df), outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IObj36EQxsCd"
      },
      "source": [
        "Restart point - if you need to clear ram, you can restart the notebook or colab session here. You can then run from the next cell to  load all the required data from a file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffCpjOnaIw0n"
      },
      "source": [
        "# Model\n",
        "\n",
        "Loads data, builds model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFRCTO-JyNET"
      },
      "source": [
        "# Only necessary if running in google colab\n",
        "%cd ./caselaw_functional_segmentation_multilingual/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HJccHXAsdOh"
      },
      "source": [
        "# Load everything. The notebook should run from here after restart.\n",
        "\n",
        "import pickle\n",
        "with open(\"cases.pkl\", \"rb\") as infile:\n",
        "    (cases, datasets, data_df) = pickle.load(infile)\n",
        "\n",
        "unique_labels = list(data_df[\"Type\"].cat.categories)\n",
        "num_labels = data_df[\"labels_all\"].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4-ggdXV8xkq"
      },
      "source": [
        "# Required when running on windows for some reason...\n",
        "# https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
        "\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDshB9r-eMPg"
      },
      "source": [
        "# Reset seed for consistent results.\n",
        "from numpy.random import seed\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def resetSeed():\n",
        "    tf.compat.v1.set_random_seed(1)\n",
        "    seed(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1psU_2pZxI0H"
      },
      "source": [
        "The following cell defines the model and some utility functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwrdpFJbIzqs"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "\n",
        "# Relevant references:\n",
        "# https://machinelearningmastery.com/develop-bidirectional-lstm-sequence-classification-python-keras/\n",
        "# https://keras.io/examples/lstm_stateful/\n",
        "# https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.datasets import imdb\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "def getData(selectedCases):\n",
        "    # Load data from list of cases, transform into format expected by keras\n",
        "  X = []\n",
        "  y = []\n",
        "  for case in selectedCases:\n",
        "    X.append(case[\"embs_ext\"])\n",
        "    y.append(case[\"label_ext\"])\n",
        "  y2 = []\n",
        "\n",
        "  # One-hot encode labels\n",
        "  for case in y:\n",
        "    lss = []\n",
        "    for sample in case:\n",
        "      ls = [0]*num_labels\n",
        "      ls[sample] = 1\n",
        "      lss.append(ls)\n",
        "    y2.append(lss)\n",
        "\n",
        "  num_samples = len(X)\n",
        "  length = len(X[0])\n",
        "  features = len(X[0][0])\n",
        "  X = np.array(X)\n",
        "  y = np.array(y2)\n",
        "  X = X.reshape(num_samples, length, features)\n",
        "  y = y.reshape(num_samples, length, num_labels)\n",
        "  \n",
        "  return X,y\n",
        "\n",
        "def trainModel(train_cases, val_cases):\n",
        "    resetSeed()\n",
        "    x_train, y_train = getData(train_cases)\n",
        "    num_samples = len(x_train)\n",
        "    length = len(x_train[0])\n",
        "    features = len(x_train[0][0])\n",
        "    X_val, Y_val = getData(val_cases)\n",
        "    print (length, features)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ## Model\n",
        "    model = Sequential()\n",
        "    model.add(Masking(mask_value=0., input_shape=(length, features)))\n",
        "    model.add(Bidirectional(GRU(256,stateful=False,return_sequences=True, input_shape=(length, features), dropout=0.2)))\n",
        "    model.add(TimeDistributed(Dense(num_labels, activation='softmax')))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    print (model.summary())\n",
        "\n",
        "\n",
        "    ## Callbacks\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                                patience=2, min_lr=1e-7, verbose=1)\n",
        "    checkpoint_filepath = './tmp/checkpoint'\n",
        "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=80, verbose=1, mode='auto')\n",
        "    mcp_save = ModelCheckpoint(checkpoint_filepath, save_best_only=True, monitor='val_accuracy', mode='max', save_weights_only=True,)\n",
        "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50, verbose=1, epsilon=1e-4, mode='min')\n",
        "\n",
        "    ## Train\n",
        "    history = model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=1000,\n",
        "            validation_data=(X_val, Y_val),\n",
        "            callbacks=[ mcp_save, earlyStopping, reduce_lr_loss])\n",
        "    plot_graphs(history, \"accuracy\")\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifns1SKeylYM"
      },
      "source": [
        "Function to plot history of train and val scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLqBcwL6V9al"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5Z1J1Asy8i8"
      },
      "source": [
        "Function to test model on a number of cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tib8emBSIzqt"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def testModel(model, test_cases):\n",
        "    x_test, y_test = getData(test_cases)\n",
        "    y_pred = model.predict(x_test)\n",
        "    test = test_cases\n",
        "    print (y_pred.shape)\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    # Remove the padded part of the case for evaluation purposes.\n",
        "    for a, sample in enumerate(y_pred):\n",
        "        for b in range(test[a][\"original_length\"]):\n",
        "            sentence_pred = sample[b]\n",
        "            preds.append(argmax(sentence_pred))\n",
        "            trues.append(test[a][\"labels\"][b])\n",
        "    return classification_report(trues, preds, target_names=unique_labels, output_dict=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOYLxJ3ezHg3"
      },
      "source": [
        "Function to get relevant folds for training, test and eval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ACquTt0QIF8"
      },
      "source": [
        "def getFolds(index):\n",
        "    eval_folds = set([index])\n",
        "    test_folds = set([(index + 1) % 10])\n",
        "    train_folds = set([(index + 2 + n) % 10 for n in range(8)])\n",
        "    return (train_folds, eval_folds, test_folds)\n",
        "\n",
        "for n in range(10):\n",
        "    print(getFolds(n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blcCXWE7zcpw"
      },
      "source": [
        "These functions retrieve the relevant cases, depending on dataset and fold. They correspond to the hypotheses in the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGB3XLN4I_ui"
      },
      "source": [
        "def getCases(dataset, folds):\n",
        "    # H1 - get cases for training from a single dataset\n",
        "    return [case for case in cases if case[\"dataset\"] == dataset and case[\"fold\"] in folds]\n",
        "\n",
        "def getCasesExcept(dataset, folds):\n",
        "    # H2 - get cases for training from all dataset except the supplied dataset\n",
        "    return [case for case in cases if case[\"dataset\"] != dataset and case[\"fold\"] in folds]\n",
        "\n",
        "def getAllCases(folds):\n",
        "    # H3 - get cases from all datasets\n",
        "    return [case for case in cases if case[\"fold\"] in folds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lefA3iMvz3le"
      },
      "source": [
        "This cell sets up a list of all results, and a function to save results in a standard format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x4Z16cbN6lY"
      },
      "source": [
        "import json\n",
        "allResults = []\n",
        "def addResults(model, train, test, results, fold_index):\n",
        "    newRes = {\n",
        "        \"model\": model,\n",
        "        \"train\": train,\n",
        "        \"test\": test,\n",
        "        \"fold_index\": fold_index,\n",
        "        \"results\": results\n",
        "    }\n",
        "    print (\"Weighted F1-score: \",results[\"weighted avg\"][\"f1-score\"])\n",
        "    allResults.append(newRes)\n",
        "    print (newRes)\n",
        "    with open(\"results_tmp.json\", \"w\") as outfile:\n",
        "        json.dump(allResults, outfile)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiqpbAiQ1kGz"
      },
      "source": [
        "# Experiments\n",
        "This section contains the different hypotheses that we evaluate in the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJMoeJ2DYn39"
      },
      "source": [
        "## Dummy\n",
        "This dummy classifier is used as a baseline for H1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KSP4c5xjNnz"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "def trainDummy(casesProv):\n",
        "    X = []\n",
        "    y = []\n",
        "    for case in casesProv:\n",
        "        for i, sent in enumerate(case[\"sents\"]):\n",
        "            X.append(sent)\n",
        "            y.append(case[\"labels\"][i])\n",
        "    dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
        "    dummy_clf.fit(X, y)\n",
        "    return dummy_clf\n",
        "\n",
        "def testDummy(model, casesProv):\n",
        "    X = []\n",
        "    y = []\n",
        "    for case in casesProv:\n",
        "        for i, sent in enumerate(case[\"sents\"]):\n",
        "            X.append(sent)\n",
        "            y.append(case[\"labels\"][i])\n",
        "    preds = model.predict(X)\n",
        "    return classification_report(y, preds, target_names=unique_labels, output_dict=True)\n",
        "\n",
        "\n",
        "for test_dataset in datasets:\n",
        "    print (\"-------------------\")\n",
        "    print (f\"Starting dataset {test_dataset}\")\n",
        "    print (\"-------------------\")\n",
        "    for fold_index in range(10):\n",
        "        print (\"-------------------\")\n",
        "        print (f\"Starting fold index {fold_index}\")\n",
        "        print (\"-------------------\")\n",
        "        (train_folds, eval_folds, test_folds) = getFolds(fold_index)\n",
        "        train_cases = getCases(test_dataset, train_folds)\n",
        "        val_cases = getCases(test_dataset, eval_folds)\n",
        "        print (f\"Training on dataset {test_dataset}, folds {train_folds}, evaluating on {eval_folds}\")\n",
        "        model = trainDummy(train_cases+val_cases)\n",
        "        print (model)\n",
        "        #for test_dataset in datasets:\n",
        "        test_cases = getCases(test_dataset, test_folds)\n",
        "        print (f\"Model trained on {test_dataset}, evaluating on {test_dataset}, fold {test_folds}:\")\n",
        "        train = \"dummy\"\n",
        "        modelName = \"sequential\"\n",
        "        test = test_dataset\n",
        "        results = testDummy(model, test_cases)\n",
        "        print (results)\n",
        "        print (\"Weighted F1-score: \",results[\"weighted avg\"][\"f1-score\"])\n",
        "        addResults(modelName, train, test, results, fold_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZI0XO01ecWq"
      },
      "source": [
        "## H1 - Out-Context Experiment\n",
        "Trains model on single dataset, tests against each dataset, once for each 10 folds. Saves results to results table. This experiment takes a number of hours to run, depending on the speed of the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhtKosSEecWr"
      },
      "source": [
        "%%time\n",
        "from numpy import argmax\n",
        "\n",
        "for train_dataset in datasets:\n",
        "    print (\"-------------------\")\n",
        "    print (f\"Starting dataset {train_dataset}\")\n",
        "    print (\"-------------------\")\n",
        "    for fold_index in range(10):\n",
        "        print (\"-------------------\")\n",
        "        print (f\"Starting fold index {fold_index}\")\n",
        "        print (\"-------------------\")\n",
        "        (train_folds, eval_folds, test_folds) = getFolds(fold_index)\n",
        "        train_cases = getCases(train_dataset, train_folds)\n",
        "        val_cases = getCases(train_dataset, eval_folds)\n",
        "        print (f\"Training on dataset {train_dataset}, folds {train_folds}, evaluating on {eval_folds}\")\n",
        "        model, history = trainModel(train_cases, val_cases)\n",
        "        for test_dataset in datasets:\n",
        "            test_cases = getCases(test_dataset, test_folds)\n",
        "            print (f\"Model trained on {train_dataset}, evaluating on {test_dataset}, fold {test_folds}:\")\n",
        "            train = train_dataset\n",
        "            modelName = \"sequential\"\n",
        "            test = test_dataset\n",
        "            results = testModel(model, test_cases)\n",
        "            addResults(modelName, train, test, results, fold_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgU-01SUfCRk"
      },
      "source": [
        "## H2 - Pooled Out-Context Experiment\n",
        "Trains model on all datasets excluding the target dataset, tests against the target dataset, once for each 10 folds. Saves results to results table. WARNING: High RAM usage - likely to crash when running on google colab.\n",
        "\n",
        "Can take a couple of hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oCbAVFSe6gt"
      },
      "source": [
        "%%time\n",
        "from numpy import argmax\n",
        "import json\n",
        "\n",
        "\n",
        "for excl_dataset in datasets:\n",
        "    print (\"-------------------\")\n",
        "    print (f\"Starting dataset {excl_dataset}\")\n",
        "    print (\"-------------------\")\n",
        "    for fold_index in range(10):\n",
        "        print (\"-------------------\")\n",
        "        print (f\"Starting fold index {fold_index}\")\n",
        "        print (\"-------------------\")\n",
        "        (train_folds, eval_folds, test_folds) = getFolds(fold_index)\n",
        "        train_cases = getCasesExcept(excl_dataset, train_folds)\n",
        "        val_cases = getCasesExcept(excl_dataset, eval_folds)\n",
        "        test_cases = getCases(excl_dataset, test_folds)\n",
        "        model, history = trainModel(train_cases, val_cases)\n",
        "        print (f\"Model trained on all except test, evaluating on {excl_dataset}:\")\n",
        "        train = \"all-excl\"\n",
        "        modelName = \"sequential\"\n",
        "        test = excl_dataset\n",
        "        results = testModel(model, test_cases)\n",
        "        addResults(modelName, train, test, results, fold_index)\n",
        "    print (f\"Finished dataset {excl_dataset}. Results:\")\n",
        "    print (allResults)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ynkJuVeXav"
      },
      "source": [
        "## H3 - Pooled With In-Context Experiment\n",
        "Trains model on all datasets, tests against each dataset, once for each 10 folds. Saves results to results table.\n",
        "\n",
        "WARNING: High RAM usage - likely to crash when running on google colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUTVi9ZBIzqt"
      },
      "source": [
        "%%time\n",
        "for fold_index in range(10):\n",
        "    print (\"-------------------\")\n",
        "    print (f\"Starting fold index {fold_index}\")\n",
        "    print (\"-------------------\")\n",
        "    (train_folds, eval_folds, test_folds) = getFolds(fold_index)\n",
        "    train_cases = getAllCases(train_folds)\n",
        "    val_cases = getAllCases(eval_folds)\n",
        "    model, history = trainModel(train_cases, val_cases)\n",
        "    for test_dataset in datasets:\n",
        "        print (f\"Model trained on all, evaluating on {test_dataset}:\")\n",
        "        train = \"all\"\n",
        "        test = test_dataset\n",
        "        modelName = \"sequential\"\n",
        "        test_cases = getCases(test_dataset, test_folds)\n",
        "        results = testModel(model, test_cases)\n",
        "        addResults(modelName, train, test, results, fold_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al4hdGVM28Cd"
      },
      "source": [
        "## Save results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ABqwSwy3DbT"
      },
      "source": [
        "Save results to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcTS1hzN2_6A"
      },
      "source": [
        "with open(\"results_final.json\", \"w\") as outfile:\n",
        "        json.dump(allResults, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j71Xj01Wpm1g"
      },
      "source": [
        "# Visualization\n",
        "This section produces two visualizations of the cases, used in the discussion section of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxT2CYOvxhJf"
      },
      "source": [
        "## Average case visualization\n",
        "Here, we take the average embedding of each case, project them to two dimensions using a Principal Component Analysis, draw a graph of the visualization, segmenting the cases by which dataset they are from.\n",
        "\n",
        "Code based on `Principle Component Analysis (PCA) for Data Visualization` by Michael Galarnyk, licensed under the [MIT license](https://opensource.org/licenses/MIT), available here: https://github.com/mGalarnyk/Python_Tutorials/blob/master/Sklearn/PCA/PCA_Data_Visualization_Iris_Dataset_Blog.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut94iyAfqsxu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "embeddings = []\n",
        "for case in cases:\n",
        "    embs = case[\"embs\"]\n",
        "    avg = np.mean(embs, axis=0)\n",
        "    embeddings.append(avg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4WEZL6YnzYI"
      },
      "source": [
        "case_df = pd.DataFrame({\n",
        "    \"dataset\": [case[\"dataset\"] for case in cases],\n",
        "    \"embedding\": embeddings\n",
        "})\n",
        "\n",
        "\n",
        "x = embeddings\n",
        "y = [case[\"dataset\"] for case in cases]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoWjejMrnnrZ"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(x)\n",
        "print (principalComponents.shape)\n",
        "principalDf = pd.DataFrame(data = principalComponents,\n",
        "             columns = ['pc1', 'pc2'])\n",
        "pcaDF = pd.concat([principalDf, case_df[['dataset']]], axis = 1)\n",
        "print (pcaDF.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyQfZ2sXwO9V"
      },
      "source": [
        "colors = [\n",
        "    '#7fc97f',\n",
        "    '#beaed4',\n",
        "    '#fdc086',\n",
        "    '#ffff99',\n",
        "    '#386cb0',\n",
        "    '#f0027f',\n",
        "    '#bf5b17',\n",
        "    '#666666',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8FydOcD8FIS"
      },
      "source": [
        "trainNameMapping = {\n",
        "            \"dummy\": \"Dummy\",\n",
        "            \"Canada-EN-1\": \"Canada\",\n",
        "            \"Czech_Republic-CZ-1\": \"Czech R.\",\n",
        "            \"France-FR-1\": \"France\",\n",
        "            \"Germany-DE-1\": \"Germany\",\n",
        "            \"Italy-IT-1\": \"Italy\",\n",
        "            \"Poland-PL-1\": \"Poland\",\n",
        "            \"United_States-EN-1\": \"U.S.A. I\",\n",
        "            \"United_States-EN-2\": \"U.S.A. II\",\n",
        "            \"all\": \"All\",\n",
        "            \"all-excl\": \"All -target\"\n",
        "\n",
        "}\n",
        "\n",
        "targetsProper = []\n",
        "for target in datasets:\n",
        "    targetsProper.append(trainNameMapping[target])\n",
        "print (targetsProper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghre-6s0pR3o"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('legend',fontsize=16)\n",
        "\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "plt.axis('off')\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "\n",
        "targets = datasets\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = pcaDF['dataset'] == target\n",
        "    ax.scatter(pcaDF.loc[indicesToKeep, 'pc1']\n",
        "               , pcaDF.loc[indicesToKeep, 'pc2']\n",
        "               , c = color\n",
        "               , s = 15)\n",
        "ax.legend(targetsProper)\n",
        "plt.savefig('PCA.pdf', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmhJ7yO82JKK"
      },
      "source": [
        "## Cases visualization\n",
        "Visualizes the distribution of labels in the cases for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bNk6nXt2NUO"
      },
      "source": [
        "%%time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trainNameMapping = {\n",
        "            \"dummy\": \"Dummy\",\n",
        "            \"Canada-EN-1\": \"Canada\",\n",
        "            \"Czech_Republic-CZ-1\": \"Czech R.\",\n",
        "            \"France-FR-1\": \"France\",\n",
        "            \"Germany-DE-1\": \"Germany\",\n",
        "            \"Italy-IT-1\": \"Italy\",\n",
        "            \"Poland-PL-1\": \"Poland\",\n",
        "            \"United_States-EN-1\": \"U.S.A. I\",\n",
        "            \"United_States-EN-2\": \"U.S.A. II\",\n",
        "            \"all\": \"All\",\n",
        "            \"all-excl\": \"All -target\"\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "plt.rcParams[\"axes.grid\"] = False\n",
        "fig = plt.figure(figsize = (20,10))\n",
        "plt.gca().invert_yaxis()\n",
        "plt.legend(unique_labels)\n",
        "plt.axis('off')\n",
        "\n",
        "colors = [\n",
        "    \"#f3722c\",\n",
        "    \"#f9c74f\",\n",
        "    \"#43aa8b\"\n",
        "]\n",
        "\n",
        "for i, dataset in enumerate(datasets):\n",
        "    ax = fig.add_subplot(2,4,i+1)\n",
        "    ax.invert_yaxis()\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(trainNameMapping[dataset], fontsize = 36)\n",
        "    dCases = [case for case in cases if case[\"dataset\"] == dataset]\n",
        "    for a, case in enumerate(dCases):\n",
        "        caseLen = len(case[\"sents\"])\n",
        "        for b, label in enumerate(case[\"labels\"]):\n",
        "            startY = b/caseLen\n",
        "            endY = (b+1)/caseLen\n",
        "            line, = ax.plot([a, a], [startY, endY], color=colors[label], linewidth=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}